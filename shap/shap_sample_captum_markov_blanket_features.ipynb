{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install captum\n",
    "!pip install pytorch-lightning"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8t2cddDAS-Zh",
    "outputId": "873d0f21-5fa1-4194-eea4-bc8b696cdf6b",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.304250200Z",
     "start_time": "2024-05-01T20:58:49.821876Z"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: captum in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from captum) (3.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from captum) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.6 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from captum) (1.12.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from captum) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from torch>=1.6->captum) (4.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from matplotlib->captum) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from matplotlib->captum) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from matplotlib->captum) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from matplotlib->captum) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from matplotlib->captum) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from matplotlib->captum) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from matplotlib->captum) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from matplotlib->captum) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from matplotlib->captum) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tqdm->captum) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->captum) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages)\n",
      "DEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (1.7.7)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pytorch-lightning) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.9.* in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pytorch-lightning) (1.12.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pytorch-lightning) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2023.6.0)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pytorch-lightning) (2.13.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pytorch-lightning) (0.10.0)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pytorch-lightning) (0.3.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pytorch-lightning) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pytorch-lightning) (4.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.5)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.56.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.4.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (65.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.38.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (6.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.16.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->pytorch-lightning) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\cristiane\\documents\\ufmg\\arquivos_dissertacao\\projeto\\venv\\lib\\site-packages)\n",
      "DEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import dataset utils\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import importlib\n",
    "if importlib.util.find_spec('ipywidgets') is not None:\n",
    "    from tqdm.auto import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ],
   "metadata": {
    "id": "P1oHfLwBTEDo",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.304250200Z",
     "start_time": "2024-05-01T20:58:59.093731800Z"
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataframe = pd.read_csv('../data/final_novo.csv', sep=';')\n",
    "dataframe.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "Engty10UsN7e",
    "outputId": "37b916f1-43e2-464d-f91c-fab2f19f71f2",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.304250200Z",
     "start_time": "2024-05-01T20:58:59.119369600Z"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "              Chave sexo  Estado_civil  Status_empl  Licenca  Tipo_Resid  \\\n0  NDAR_INVLE566FK2    M           3.0          NaN      0.0         3.0   \n1  NDAR_INVMA818VXP    F           1.0          3.0      0.0         4.0   \n2  NDAR_INVHY103MHY    F           1.0          2.0      0.0         1.0   \n3  NDAR_INVEC849VWE    F           1.0          3.0      0.0         1.0   \n4  NDAR_INVHF792VJY    F           4.0          2.0      0.0         1.0   \n\n   Residencia  Alcoolatra  Droga  Suic_familia  ...  \\\n0         1.0           0      0             1  ...   \n1         3.0           0      0             1  ...   \n2         2.0           0      0             1  ...   \n3         3.0           0      0             1  ...   \n4         NaN           1      0             1  ...   \n\n   Eixo I: Panico sem agorafobia  Eixo I: Fobia especifica  \\\n0                            0.0                       0.0   \n1                            NaN                       NaN   \n2                            0.0                       0.0   \n3                            NaN                       NaN   \n4                            0.0                       0.0   \n\n   Eixo I: Fobia social  Eixo I: Obsessivo-compulsivo  \\\n0                   0.0                           0.0   \n1                   NaN                           NaN   \n2                   0.0                           0.0   \n3                   NaN                           NaN   \n4                   0.0                           0.0   \n\n   Eixo I: Estresse pos-traumatico  Eixo I: Ansiedade generalizada  \\\n0                              0.0                             0.0   \n1                              NaN                             NaN   \n2                              0.0                             0.0   \n3                              NaN                             NaN   \n4                              0.0                             0.0   \n\n   Eixo II: Personalidade paranoica  Eixo II: Transtorno de personalidade  \\\n0                               0.0                                   0.0   \n1                               NaN                                   NaN   \n2                               0.0                                   0.0   \n3                               NaN                                   NaN   \n4                               0.0                                   0.0   \n\n   TOC  idade  \n0  3.0   40.0  \n1  0.0   20.0  \n2  0.0   20.0  \n3  6.0   30.0  \n4  0.0   40.0  \n\n[5 rows x 69 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Chave</th>\n      <th>sexo</th>\n      <th>Estado_civil</th>\n      <th>Status_empl</th>\n      <th>Licenca</th>\n      <th>Tipo_Resid</th>\n      <th>Residencia</th>\n      <th>Alcoolatra</th>\n      <th>Droga</th>\n      <th>Suic_familia</th>\n      <th>...</th>\n      <th>Eixo I: Panico sem agorafobia</th>\n      <th>Eixo I: Fobia especifica</th>\n      <th>Eixo I: Fobia social</th>\n      <th>Eixo I: Obsessivo-compulsivo</th>\n      <th>Eixo I: Estresse pos-traumatico</th>\n      <th>Eixo I: Ansiedade generalizada</th>\n      <th>Eixo II: Personalidade paranoica</th>\n      <th>Eixo II: Transtorno de personalidade</th>\n      <th>TOC</th>\n      <th>idade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NDAR_INVLE566FK2</td>\n      <td>M</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NDAR_INVMA818VXP</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NDAR_INVHY103MHY</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NDAR_INVEC849VWE</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>30.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NDAR_INVHF792VJY</td>\n      <td>F</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 69 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#último grafo cris: 8 features\n",
    "selected = [\"Suic_familia\",\n",
    "    \"Capaz de tomar decisões importantes\",\n",
    "    \"Estudante\",\n",
    "    \"Hipocondriase\",\n",
    "    \"Sentimentos_culpa\",\n",
    "    \"Trabalho e interesses\",\n",
    "    'Dep_familia',\n",
    "    'Alc_familia',\n",
    "    'Capaz de desfrutar das coisas',\n",
    "    'Droga',\n",
    "    'Suicidio',\n",
    "    'Ansiedade']\n"
   ],
   "metadata": {
    "id": "akmY3RSRsZZO",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.304250200Z",
     "start_time": "2024-05-01T20:58:59.181856800Z"
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataframe['sexo'].replace({'M': 0, 'F': 1}, inplace=True)\n",
    "dataframe['sexo'].fillna(0, inplace=True)\n",
    "\n",
    "df_suic = dataframe[selected]\n",
    "\n",
    "df_suic.dropna(inplace=True)\n",
    "df_suic = df_suic.astype(int)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VGeRd0jfsbQw",
    "outputId": "cfce9568-5523-49a6-8f2c-e29d36768156",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.304250200Z",
     "start_time": "2024-05-01T20:58:59.197473700Z"
    }
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristiane\\AppData\\Local\\Temp\\ipykernel_31000\\156640811.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_suic.dropna(inplace=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_suic"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Qho1lqG7DXSS",
    "outputId": "721d2a56-5456-4f90-836c-53f9eea1885b",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.304250200Z",
     "start_time": "2024-05-01T20:58:59.219638200Z"
    }
   },
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "      Suic_familia  Capaz de tomar decisões importantes  Estudante  \\\n0                1                                    2          0   \n1                1                                    1          0   \n2                1                                    2          0   \n3                1                                    1          0   \n4                1                                    2          0   \n...            ...                                  ...        ...   \n3948             1                                    2          0   \n3949             1                                    1          0   \n3950             1                                    1          0   \n3951             1                                    2          0   \n3952             1                                    1          1   \n\n      Hipocondriase  Sentimentos_culpa  Trabalho e interesses  Dep_familia  \\\n0                 2                  3                      2            1   \n1                 0                  2                      2            1   \n2                 0                  3                      3            1   \n3                 3                  4                      3            1   \n4                 1                  2                      4            1   \n...             ...                ...                    ...          ...   \n3948              0                  3                      2            1   \n3949              2                  2                      2            1   \n3950              2                  3                      3            1   \n3951              1                  1                      2            1   \n3952              0                  2                      3            1   \n\n      Alc_familia  Capaz de desfrutar das coisas  Droga  Suicidio  Ansiedade  \n0               1                              2      0         2          2  \n1               1                              1      0         1          2  \n2               1                              2      0         0          2  \n3               1                              1      0         3          2  \n4               1                              3      0         1          3  \n...           ...                            ...    ...       ...        ...  \n3948            1                              2      0         2          3  \n3949            1                              1      0         1          2  \n3950            1                              1      0         2          2  \n3951            1                              2      0         0          2  \n3952            1                              1      0         0          2  \n\n[3933 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Suic_familia</th>\n      <th>Capaz de tomar decisões importantes</th>\n      <th>Estudante</th>\n      <th>Hipocondriase</th>\n      <th>Sentimentos_culpa</th>\n      <th>Trabalho e interesses</th>\n      <th>Dep_familia</th>\n      <th>Alc_familia</th>\n      <th>Capaz de desfrutar das coisas</th>\n      <th>Droga</th>\n      <th>Suicidio</th>\n      <th>Ansiedade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3948</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3949</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3950</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3951</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3952</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>3933 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class MyDataset(Dataset):\n",
    " \n",
    "  def __init__(self, input_dataframe, split=\"train\", target=\"Suicidio\", ignore_columns=[], train_ratio=0.8): \n",
    "    \n",
    "    self.split = split\n",
    "    self.target = target\n",
    "    self.ignore_columns = ignore_columns\n",
    "\n",
    "    for coll in self.ignore_columns:\n",
    "       if coll in input_dataframe.columns:\n",
    "        input_dataframe = input_dataframe.drop(coll, axis=1)\n",
    "\n",
    "    self.classification_dim = len(input_dataframe[self.target].unique())\n",
    "    self.data_dim = len(input_dataframe.columns) - 1\n",
    "    self.embbeding_dim = input_dataframe.max().max() + 1\n",
    "\n",
    "    y = input_dataframe[target].values \n",
    "    x = input_dataframe.drop(target, axis = 1).values \n",
    "\n",
    "    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(x, y, test_size=1-train_ratio, random_state=42) \n",
    "\n",
    "  def __len__(self):\n",
    "    if self.split == \"train\":\n",
    "      return len(self.x_train)\n",
    "    elif self.split == \"test\":\n",
    "      return len(self.x_test)\n",
    "    else:\n",
    "      raise ValueError(\"Split must be train or test\")\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "      target = torch.zeros(self.classification_dim) \n",
    "      if self.split == \"train\":\n",
    "          target[self.y_train[idx]] = 1\n",
    "          return (torch.tensor(self.x_train[idx]), target) \n",
    "      elif self.split == \"test\":\n",
    "          target[self.y_test[idx]] = 1\n",
    "          return (torch.tensor(self.x_test[idx]), target)\n",
    "      else:\n",
    "          raise ValueError(\"Split must be train or test\")"
   ],
   "metadata": {
    "id": "mUT8pPB-snu2",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.304250200Z",
     "start_time": "2024-05-01T20:58:59.250893500Z"
    }
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# instanciando o dataset \n",
    "train_dataset = MyDataset(df_suic, split=\"train\", target=\"Suicidio\", ignore_columns=[], train_ratio=0.8)\n",
    "test_dataset = MyDataset(df_suic, split=\"test\", target=\"Suicidio\", ignore_columns=[], train_ratio=0.8)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False) \n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.304250200Z",
     "start_time": "2024-05-01T20:58:59.266471500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a MLP model with N layers: rede neural de 2 camadas\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128, n_layers=2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "    \n",
    "        self.layers = nn.ModuleList() \n",
    "        self.layers.append(nn.Linear(self.input_dim, self.hidden_dim)) \n",
    "        for i in range(self.n_layers - 1):\n",
    "            self.layers.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "            self.layers.append(nn.Dropout(0.5)) \n",
    "            self.layers.append(nn.LeakyReLU())\n",
    "            \n",
    "        self.layers.append(nn.Linear(self.hidden_dim, self.output_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)           \n",
    "        return x\n"
   ],
   "metadata": {
    "id": "hq_fWixTstzH",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.451395300Z",
     "start_time": "2024-05-01T20:58:59.297711700Z"
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a Model with a embbeding layer and a MLP\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, embbeding_dim, hidden_out, hidden_dim=128, n_layers=2):   \n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embbeding_dim = embbeding_dim\n",
    "        self.embbeding_out = hidden_out\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embbeding_layer = nn.Embedding(self.embbeding_dim, self.embbeding_out) \n",
    "        self.mlp = MLP(self.input_dim * self.embbeding_out, self.output_dim, self.hidden_dim, self.n_layers) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embbeding_layer(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.mlp(x)\n",
    "        ## classification\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "id": "Kpr4m-W0syV-",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.504767400Z",
     "start_time": "2024-05-01T20:58:59.319875Z"
    }
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ClassificationModel(\n",
      "  (embbeding_layer): Embedding(6, 20)\n",
      "  (mlp): MLP(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=220, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): LeakyReLU(negative_slope=0.01)\n",
      "      (7): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (8): Dropout(p=0.5, inplace=False)\n",
      "      (9): LeakyReLU(negative_slope=0.01)\n",
      "      (10): Linear(in_features=128, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ") \n",
      "\n",
      "Batch shape: torch.Size([128, 11]) \n",
      "\n",
      "Output shape: torch.Size([128, 5]) \n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "example_batch = next(iter(train_loader))\n",
    "example_data, example_targets = example_batch\n",
    "\n",
    "model = ClassificationModel(train_dataset.data_dim, train_dataset.classification_dim, train_dataset.embbeding_dim, hidden_out=20, hidden_dim=128, n_layers=4) # Cadar tirou\n",
    "print('model:', model, '\\n')\n",
    "\n",
    "print(\"Batch shape:\", example_data.shape,'\\n') \n",
    "res = model(example_data)\n",
    "print(\"Output shape:\", res.shape,'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.504767400Z",
     "start_time": "2024-05-01T20:58:59.351120200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Make Lightning Module\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics import MaxMetric, MeanMetric\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "class BaseModel(LightningModule):\n",
    "    \"\"\"A LightningModule organizes your PyTorch code into 6 sections:\n",
    "        - Computations (init)\n",
    "        - Validation loop (validation_step)\n",
    "        - Train loop (training_step)\n",
    "        - Test loop (test_step)\n",
    "        - Prediction Loop (predict_step)\n",
    "        - Optimizers and LR Schedulers (configure_optimizers)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, embedding_dim, embedding_out, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = ClassificationModel(input_dim, output_dim, embedding_dim, embedding_out, hidden_dim=hidden_dim, n_layers=2)\n",
    "        self.lr = 1e-3 # taxa de aprendizado: 0.001\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # metric objects for calculating and averaging accuracy across batches\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=5)\n",
    "        \n",
    "        # for tracking best so far validation accuracy\n",
    "        self.val_acc_best = MaxMetric()\n",
    "    \n",
    "    def step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x).squeeze().float()\n",
    "        # loss function\n",
    "        loss = F.binary_cross_entropy(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y.int())\n",
    "        return loss, acc\n",
    "   \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.step(batch)\n",
    "        self.log('train_loss', loss, prog_bar=True)        \n",
    "        self.log('train_acc', acc,  prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self.step(batch)\n",
    "        self.log('val_loss', loss)      \n",
    "        self.log('val_acc', acc,  prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    # gradiente\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Choose what optimizers and learning-rate schedulers to use in your optimization.\n",
    "        Normally you'd need one. But in the case of GANs or similar you might have multiple.\n",
    "\n",
    "        Examples:\n",
    "            https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#configure-optimizers\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ],
   "metadata": {
    "id": "4MgFJBB6s9zH",
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.504767400Z",
     "start_time": "2024-05-01T20:58:59.382393200Z"
    }
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Initialize model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mBaseModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassification_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel:\u001B[39m\u001B[38;5;124m'\u001B[39m, model,\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[40], line 24\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[1;34m(self, input_dim, output_dim, embedding_dim, embedding_out, hidden_dim)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_hyperparameters()\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# metric objects for calculating and averaging accuracy across batches\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccuracy \u001B[38;5;241m=\u001B[39m \u001B[43mAccuracy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmulticlass\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# for tracking best so far validation accuracy\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_acc_best \u001B[38;5;241m=\u001B[39m MaxMetric()\n",
      "File \u001B[1;32m~\\Documents\\UFMG\\Arquivos_Dissertacao\\Projeto\\venv\\lib\\site-packages\\torchmetrics\\classification\\accuracy.py:491\u001B[0m, in \u001B[0;36mAccuracy.__new__\u001B[1;34m(cls, threshold, num_classes, average, mdmc_average, ignore_index, top_k, multiclass, subset_accuracy, task, num_labels, multidim_average, validate_args, **kwargs)\u001B[0m\n\u001B[0;32m    489\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    490\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(num_classes, \u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m--> 491\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(top_k, \u001B[38;5;28mint\u001B[39m)\n\u001B[0;32m    492\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m MulticlassAccuracy(num_classes, top_k, average, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    493\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = BaseModel(input_dim=train_dataset.data_dim, output_dim=train_dataset.classification_dim, embedding_dim=100, embedding_out=64, hidden_dim=128)\n",
    "print('model:', model,'\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T20:58:59.702718Z",
     "start_time": "2024-05-01T20:58:59.420158Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import trainer\n",
    "from pytorch_lightning.trainer import Trainer"
   ],
   "metadata": {
    "id": "gsvEYG92tBDP",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.520395800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Import callbacks\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Initialize callbacks\n",
    "\n",
    "# Salve o modelo periodicamente monitorando uma quantidade.\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/', \n",
    "    filename='best-checkpoint', \n",
    "    save_top_k=1, \n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "# Monitore uma métrica e interrompa o treinamento quando ela parar de melhorar.\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0.05, \n",
    "    patience=10, \n",
    "    verbose=False, \n",
    "    mode='min' \n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stopping]\n",
    "\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = Trainer(\n",
    "    #accelerator='gpu',\n",
    "    accelerator='cpu', \n",
    "    devices=1, \n",
    "    check_val_every_n_epoch=10, \n",
    "    log_every_n_steps=10, \n",
    "    callbacks=callbacks, \n",
    "    auto_lr_find=True, \n",
    "    enable_progress_bar=False\n",
    "    ) "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xr9oDvjQTD9b",
    "outputId": "2a73c3b6-55df-4dde-c4a7-7410a938542a",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.520395800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.536016200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#odel = BaseModel.load_from_checkpoint(\"/content/best-checkpoint-v31.ckpt\")"
   ],
   "metadata": {
    "id": "s_IBwTbFk3yg",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.536016200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#from captum.attr import ShapleyValues\n",
    "from captum.attr import ShapleyValueSampling"
   ],
   "metadata": {
    "id": "_BTMwOerwbDq",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.536016200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_suic_0 = df_suic.loc[df_suic.Suicidio == 0]\n",
    "df_suic_1 = df_suic.loc[df_suic.Suicidio == 1]\n",
    "df_suic_2 = df_suic.loc[df_suic.Suicidio == 2]\n",
    "df_suic_3 = df_suic.loc[df_suic.Suicidio == 3]\n",
    "df_suic_4 = df_suic.loc[df_suic.Suicidio == 4]"
   ],
   "metadata": {
    "id": "_iDp2p0_zoKE",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.551638300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "svs = ShapleyValueSampling(model.model.forward)"
   ],
   "metadata": {
    "id": "QvtNIzROUkXf",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.551638300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample_df_suic_0 = df_suic_0.sample(n=10, random_state=42)\n",
    "sample_df_suic_1 = df_suic_1.sample(n=10, random_state=42)\n",
    "sample_df_suic_2 = df_suic_2.sample(n=10, random_state=42)\n",
    "sample_df_suic_3 = df_suic_3.sample(n=10, random_state=42)\n",
    "#sample_df_suic_4 = df_suic_4.sample(n=10, random_state=42)"
   ],
   "metadata": {
    "id": "E84ChWqoHhs8",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.567259Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tensor_suic_0 = torch.tensor(df_suic_0.drop(labels='Suicidio', axis='columns').values)\n",
    "tensor_suic_1 = torch.tensor(df_suic_1.drop(labels='Suicidio', axis='columns').values)\n",
    "tensor_suic_2 = torch.tensor(df_suic_2.drop(labels='Suicidio', axis='columns').values)\n",
    "tensor_suic_3 = torch.tensor(df_suic_3.drop(labels='Suicidio', axis='columns').values)\n",
    "tensor_suic_4 = torch.tensor(df_suic_4.drop(labels='Suicidio', axis='columns').values)"
   ],
   "metadata": {
    "id": "Is7J9Arv28Xq",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.567259Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "attr_tensor_suic_0 = svs.attribute(tensor_suic_0, target=0)\n",
    "attr_tensor_suic_1 = svs.attribute(tensor_suic_1, target=1)\n",
    "attr_tensor_suic_2 = svs.attribute(tensor_suic_2, target=2)\n",
    "attr_tensor_suic_3 = svs.attribute(tensor_suic_3, target=3)\n",
    "attr_tensor_suic_4 = svs.attribute(tensor_suic_4, target=4)"
   ],
   "metadata": {
    "id": "lnido3eD3ZWx",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.582883200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "feature_names = list(df_suic.drop(labels='Suicidio', axis='columns').columns)\n",
    "feature_names"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISJOG1k2eqgO",
    "outputId": "1d39b4b9-d888-4a94-db88-5e6b9544dfab",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.582883200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "dup0Bn03fVeF",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.582883200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Helper method to print importances and visualize distribution\n",
    "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True):\n",
    "    print(title)\n",
    "    for i in range(len(feature_names)):\n",
    "        print(feature_names[i], \": \", '%.3f'%(importances[i]))\n",
    "    x_pos = (np.arange(len(feature_names)))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.bar(x_pos, importances, align='center')\n",
    "        plt.xticks(x_pos, feature_names, wrap=True)\n",
    "        plt.xticks(rotation=20, ha='right')\n",
    "        plt.xlabel(\"Features\")\n",
    "        plt.ylabel(\"Average Feature Importances\")\n",
    "        plt.grid(True)\n",
    "        plt.title(title)"
   ],
   "metadata": {
    "id": "tU8UEnH2ba1T",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.582883200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "attr_np_0 = attr_tensor_suic_0.detach().numpy()\n",
    "attr_np_1 = attr_tensor_suic_1.detach().numpy()\n",
    "attr_np_2 = attr_tensor_suic_2.detach().numpy()\n",
    "attr_np_3 = attr_tensor_suic_3.detach().numpy()\n",
    "attr_np_4 = attr_tensor_suic_4.detach().numpy()"
   ],
   "metadata": {
    "id": "_FEbLCAL2oCr",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.598503400Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_importances(feature_names, np.mean(attr_np_0, axis=0), title=\"Classe Suícidio = 0\")\n",
    "plt.savefig(\"shap_suicidio_0.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "O-BAUyq25vdR",
    "outputId": "7dc94e96-2d83-431e-e275-64897ed008c0",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.598503400Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_importances(feature_names, np.mean(attr_np_1, axis=0), title=\"Classe Suícidio = 1\")\n",
    "plt.savefig(\"shap_suicidio_1.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "RjohyCj15v2P",
    "outputId": "7761e73a-d3a4-474d-f422-556faa9db1f8",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.607621300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_importances(feature_names, np.mean(attr_np_2, axis=0), title=\"Classe Suícidio = 2\")\n",
    "plt.savefig(\"shap_suicidio_2.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "6JegEjob3ve3",
    "outputId": "6aa0e7ad-f3ba-4cfa-dbef-221163b43471",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.611610Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_importances(feature_names, np.mean(attr_np_3, axis=0), title=\"Classe Suícidio = 3\")\n",
    "plt.savefig(\"shap_suicidio_3.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "B7iOqT2Q3zPx",
    "outputId": "f0a3a217-d549-4bde-b497-a1b8155dbf6d",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.614603100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_importances(feature_names, np.mean(attr_np_4, axis=0), title=\"Classe Suícidio = 4\")\n",
    "plt.savefig(\"shap_suicidio_4.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "g3snfuAo3yYr",
    "outputId": "f75c2861-3c06-4e9f-d984-99ca5efbd58f",
    "ExecuteTime": {
     "start_time": "2024-05-01T20:58:59.618591Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
